{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CML APIv2 を使った自動でのアプリのデプロイ\n",
    "Pinecone に必要な文脈情報を追加し、準備ができた状態で、このノートブックの内容を実行してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 必要なライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cmlapi\n",
    "import random\n",
    "import string\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 CML API クライアントを生成し、利用可能なランタイムの一覧を取得する\n",
    "このコードでは、CML（Cloudera AI）の環境に接続し、まず以下の条件に該当するランタイムを取得します。\n",
    "\n",
    "- Python 3.10 のランタイムである\n",
    "- Nvidia の GPU をサポートしている\n",
    "- エディタとして Jupyter Lab を利用できる\n",
    "  \n",
    "その上で、リストの中にある最新のランタイムを選択し、内容を一覧表示するとともに、将来のジョブ実行時に利用できるよう、ランタイムの識別子を環境変数に保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = cmlapi.default_client(url=os.getenv(\"CDSW_API_URL\").replace(\"/api/v1\", \"\"), cml_api_key=os.getenv(\"CDSW_APIV2_KEY\"))\n",
    "available_runtimes = client.list_runtimes(search_filter=json.dumps({\n",
    "    \"kernel\": \"Python 3.10\",\n",
    "    \"edition\": \"Nvidia GPU\",\n",
    "    \"editor\": \"JupyterLab\"\n",
    "}))\n",
    "print(available_runtimes)\n",
    "\n",
    "## 利用可能なランタイムを、環境の中の最新のランタイムとする（イテレータは0から始まり、1ずつ増えていきます）\n",
    "## JOB_IMAGE_ML_RUNTIME は、variable stores the ML Runtime which will be used to launch the job\n",
    "print(available_runtimes.runtimes[-1])\n",
    "print(available_runtimes.runtimes[-1].image_identifier)\n",
    "APP_IMAGE_ML_RUNTIME = available_runtimes.runtimes[-1].image_identifier\n",
    "\n",
    "## 将来のジョブ実行のために、MLのランタイムを環境変数に保存しておく\n",
    "os.environ['APP_IMAGE_ML_RUNTIME'] = APP_IMAGE_ML_RUNTIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 現在のプロジェクトを取得する\n",
    "環境変数の \"CDSW Project ID\" から現在のプロジェクトの情報を取得し、メタデータを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project = client.get_project(project_id=os.getenv(\"CDSW_PROJECT_ID\"))\n",
    "print(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 LLM アプリケーションを作成する\n",
    "\n",
    "このコードでは、\"CML - Auto created\"という名前のCMLアプリケーションを作成します。  \n",
    "プロジェクトの description や、リソースの割り当て（CPU、メモリ）についても記述しています。  \n",
    "ランタイムの識別子は、これまでの流れで取得したものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "application_request = cmlapi.CreateApplicationRequest(\n",
    "     name = \"CML - Auto created\",\n",
    "     description = \"このアプリケーションは、4_launch_hosted_app配下の create_llm_application.ipynb を使って llm_prototype_app.py を呼び出すことで作成されたものです。UI部分には Gradio UIを使用しています。\",\n",
    "     project_id = project.id,\n",
    "     subdomain = \"cml-llm-interface\",\n",
    "     script = \"4_launch_hosted_app/llm_prototype_app.py\",\n",
    "     cpu = 2,\n",
    "     memory = 8,\n",
    "     runtime_identifier = os.getenv('APP_IMAGE_ML_RUNTIME')\n",
    ")\n",
    "\n",
    "app = client.create_application(\n",
    "     project_id = project.id,\n",
    "     body = application_request\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
